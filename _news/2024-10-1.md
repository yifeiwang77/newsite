---
layout: post
date: 2024-10-01
inline: true
related_posts: false
---

6 papers were accepted to NeurIPS 2024. We inverstigated how LLMs are capable of self-correction ([paper](https://arxiv.org/pdf/2405.18634)), how to enable *representation-space in-context learning* through joint embedding models ([paper](https://arxiv.org/pdf/2405.18193)), how Transformers avoid feature collapse with LayerNorm ([paper](https://arxiv.org/pdf/2405.18781)), and why predicting data corruptions (e.g., Gaussian noise) helps learn good representations ([paper](https://openreview.net/pdf?id=NLqdudgBfy)).
