---
layout: post
title: A long announcement with details
date: 2024-10-30
inline: true
related_posts: false
---

New preprints are out, addressing why perplexity fails to reflect long-context performance and how to fix it ([paper](https://arxiv.org/pdf/2410.23771)), how interpretability techniques (eg SAEs) also endow better model robustness ([paper](https://arxiv.org/pdf/2410.21331)), and whether ICL can truly extrapolate to OOD scenarios ([paper](https://arxiv.org/pdf/2410.09695)).
